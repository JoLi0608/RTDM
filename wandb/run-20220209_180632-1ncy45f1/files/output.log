Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 13       |
|    ep_rew_mean        | 13       |
| time/                 |          |
|    fps                | 1047     |
|    iterations         | 100      |
|    time_elapsed       | 0        |
|    total_timesteps    | 500      |
| train/                |          |
|    entropy_loss       | -0.348   |
|    explained_variance | 0.702    |
|    learning_rate      | 0.0007   |
|    n_updates          | 99       |
|    policy_loss        | 0.105    |
|    value_loss         | 1.26     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 12.6     |
|    ep_rew_mean        | 12.6     |
| time/                 |          |
|    fps                | 1094     |
|    iterations         | 200      |
|    time_elapsed       | 0        |
|    total_timesteps    | 1000     |
| train/                |          |
|    entropy_loss       | -0.498   |
|    explained_variance | 0.626    |
|    learning_rate      | 0.0007   |
|    n_updates          | 199      |
|    policy_loss        | 0.0191   |
|    value_loss         | 11.1     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 14.2     |
|    ep_rew_mean        | 14.2     |
| time/                 |          |
|    fps                | 1160     |
|    iterations         | 300      |
|    time_elapsed       | 1        |
|    total_timesteps    | 1500     |
| train/                |          |
|    entropy_loss       | -0.683   |
|    explained_variance | -0.00441 |
|    learning_rate      | 0.0007   |
|    n_updates          | 299      |
|    policy_loss        | 1.71     |
|    value_loss         | 8.1      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 16.5     |
|    ep_rew_mean        | 16.5     |
| time/                 |          |
|    fps                | 1183     |
|    iterations         | 400      |
|    time_elapsed       | 1        |
|    total_timesteps    | 2000     |
| train/                |          |
|    entropy_loss       | -0.69    |
|    explained_variance | 0.0513   |
|    learning_rate      | 0.0007   |
|    n_updates          | 399      |
|    policy_loss        | 1.57     |
|    value_loss         | 7.16     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 19.4     |
|    ep_rew_mean        | 19.4     |
| time/                 |          |
|    fps                | 1169     |
|    iterations         | 500      |
|    time_elapsed       | 2        |
|    total_timesteps    | 2500     |
| train/                |          |
|    entropy_loss       | -0.656   |
|    explained_variance | 0.287    |
|    learning_rate      | 0.0007   |
|    n_updates          | 499      |
|    policy_loss        | 1.46     |
|    value_loss         | 5.2      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 22.1     |
|    ep_rew_mean        | 22.1     |
| time/                 |          |
|    fps                | 1124     |
|    iterations         | 600      |
|    time_elapsed       | 2        |
|    total_timesteps    | 3000     |
| train/                |          |
|    entropy_loss       | -0.677   |
|    explained_variance | 0.0109   |
|    learning_rate      | 0.0007   |
|    n_updates          | 599      |
|    policy_loss        | 1.12     |
|    value_loss         | 5.39     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 25.6     |
|    ep_rew_mean        | 25.6     |
| time/                 |          |
|    fps                | 1100     |
|    iterations         | 700      |
|    time_elapsed       | 3        |
|    total_timesteps    | 3500     |
| train/                |          |
|    entropy_loss       | -0.681   |
|    explained_variance | 0.0024   |
|    learning_rate      | 0.0007   |
|    n_updates          | 699      |
|    policy_loss        | 1.24     |
|    value_loss         | 4.89     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 29.6     |
|    ep_rew_mean        | 29.6     |
| time/                 |          |
|    fps                | 1080     |
|    iterations         | 800      |
|    time_elapsed       | 3        |
|    total_timesteps    | 4000     |
| train/                |          |
|    entropy_loss       | -0.651   |
|    explained_variance | 0.00665  |
|    learning_rate      | 0.0007   |
|    n_updates          | 799      |
|    policy_loss        | 1.15     |
|    value_loss         | 4.5      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 32.8     |
|    ep_rew_mean        | 32.8     |
| time/                 |          |
|    fps                | 1056     |
|    iterations         | 900      |
|    time_elapsed       | 4        |
|    total_timesteps    | 4500     |
| train/                |          |
|    entropy_loss       | -0.598   |
|    explained_variance | 0.0011   |
|    learning_rate      | 0.0007   |
|    n_updates          | 899      |
|    policy_loss        | 0.891    |
|    value_loss         | 3.98     |
------------------------------------
-------------------------------------
| rollout/              |           |
|    ep_len_mean        | 36.7      |
|    ep_rew_mean        | 36.7      |
| time/                 |           |
|    fps                | 1045      |
|    iterations         | 1000      |
|    time_elapsed       | 4         |
|    total_timesteps    | 5000      |
| train/                |           |
|    entropy_loss       | -0.559    |
|    explained_variance | -0.000655 |
|    learning_rate      | 0.0007    |
|    n_updates          | 999       |
|    policy_loss        | 1.03      |
|    value_loss         | 3.49      |
-------------------------------------
/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: [33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.
  warnings.warn(colorize("%s: %s" % ("WARN", msg % args), "yellow"))