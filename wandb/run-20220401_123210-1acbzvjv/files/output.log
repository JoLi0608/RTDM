
2022-04-01 12:32:21,241	INFO services.py:1412 -- View the Ray dashboard at [32m[1mhttp://127.0.0.1:8265
== Status ==
Current time: 2022-04-01 12:32:26 (running for 00:00:00.25)
Memory usage on this node: 9.9/16.0 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.17 GiB heap, 0.0/2.0 GiB objects
Result logdir: /Users/liwenyu/Downloads/ray_results /PPO
Number of trials: 1/1 (1 PENDING)
+-----------------+----------+-------+
| Trial name      | status   | loc   |
|-----------------+----------+-------|
| PPO_6804c_00000 | PENDING  |       |
+-----------------+----------+-------+
2022-04-01 12:32:26,871	ERROR ray_trial_executor.py:558 -- Trial PPO_6804c_00000: Unexpected error starting runner.
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/ray_trial_executor.py", line 549, in start_trial
    return self._start_trial(trial)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/ray_trial_executor.py", line 452, in _start_trial
    self.restore(trial)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/ray_trial_executor.py", line 856, in restore
    obj = TrainableUtil.checkpoint_to_object(value)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/utils/trainable.py", line 86, in checkpoint_to_object
    data_dict = TrainableUtil.pickle_checkpoint(checkpoint_path)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/utils/trainable.py", line 67, in pickle_checkpoint
    checkpoint_dir = TrainableUtil.find_checkpoint_dir(checkpoint_path)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/utils/trainable.py", line 101, in find_checkpoint_dir
    raise FileNotFoundError("Path does not exist", checkpoint_path)
FileNotFoundError: [Errno Path does not exist] /Users/liwenyu/Documents/GitHub/RTDM/Users/liwenyu/Downloads/ray_results/ARS_Hopper-v2_303ed_00000_0_2022-03-30_13-27-47/checkpoint_004300/checkpoint-4300
[36m(PPOTrainer pid=25954)[39m 2022-04-01 12:32:33,812	INFO trainer.py:2140 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.
[36m(PPOTrainer pid=25954)[39m 2022-04-01 12:32:33,812	INFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.
[36m(PPOTrainer pid=25954)[39m 2022-04-01 12:32:33,812	INFO trainer.py:779 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
== Status ==
Current time: 2022-04-01 12:32:40 (running for 00:00:13.66)
Memory usage on this node: 9.1/16.0 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.17 GiB heap, 0.0/2.0 GiB objects
Result logdir: /Users/liwenyu/Downloads/ray_results /PPO
Number of trials: 1/1 (1 ERROR)
+-----------------+----------+-------+
| Trial name      | status   | loc   |
|-----------------+----------+-------|
| PPO_6804c_00000 | ERROR    |       |
+-----------------+----------+-------+
Number of errored trials: 1
+-----------------+--------------+-------------------------------------------------------------------------------------------+
| Trial name      |   # failures | error file                                                                                |
|-----------------+--------------+-------------------------------------------------------------------------------------------|
| PPO_6804c_00000 |            1 | /Users/liwenyu/Downloads/ray_results /PPO/PPO_6804c_00000_0_2022-04-01_12-32-26/error.txt |
+-----------------+--------------+-------------------------------------------------------------------------------------------+
[36m(PPOTrainer pid=25954)[39m 2022-04-01 12:32:40,118	ERROR worker.py:430 -- Exception raised in creation task: The actor died because of an error raised in its creation task, [36mray::PPOTrainer.__init__()[39m (pid=25954, ip=127.0.0.1, repr=PPOTrainer)
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py", line 925, in _init
[36m(PPOTrainer pid=25954)[39m     raise NotImplementedError
[36m(PPOTrainer pid=25954)[39m NotImplementedError
[36m(PPOTrainer pid=25954)
[36m(PPOTrainer pid=25954)[39m During handling of the above exception, another exception occurred:
[36m(PPOTrainer pid=25954)
[36m(PPOTrainer pid=25954)[39m [36mray::PPOTrainer.__init__()[39m (pid=25954, ip=127.0.0.1, repr=PPOTrainer)
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py", line 746, in __init__
[36m(PPOTrainer pid=25954)[39m     super().__init__(config, logger_creator, remote_checkpoint_dir,
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/trainable.py", line 124, in __init__
[36m(PPOTrainer pid=25954)[39m     self.setup(copy.deepcopy(self.config))
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py", line 822, in setup
[36m(PPOTrainer pid=25954)[39m     self.workers = self._make_workers(
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py", line 1995, in _make_workers
[36m(PPOTrainer pid=25954)[39m     return WorkerSet(
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py", line 101, in __init__
[36m(PPOTrainer pid=25954)[39m     remote_spaces = ray.get(self.remote_workers(
[36m(PPOTrainer pid=25954)[39m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=25956, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fbfea6385e0>)
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 541, in __init__
[36m(PPOTrainer pid=25954)[39m     self.policy_dict = _determine_spaces_for_multi_agent_dict(
[36m(PPOTrainer pid=25954)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 1657, in _determine_spaces_for_multi_agent_dict
[36m(PPOTrainer pid=25954)[39m     raise ValueError(
[36m(PPOTrainer pid=25954)[39m ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!
[36m(RolloutWorker pid=25956)[39m 2022-04-01 12:32:40,108	ERROR worker.py:430 -- Exception raised in creation task: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=25956, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fbfea6385e0>)
[36m(RolloutWorker pid=25956)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 541, in __init__
[36m(RolloutWorker pid=25956)[39m     self.policy_dict = _determine_spaces_for_multi_agent_dict(
[36m(RolloutWorker pid=25956)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 1657, in _determine_spaces_for_multi_agent_dict
[36m(RolloutWorker pid=25956)[39m     raise ValueError(
[36m(RolloutWorker pid=25956)[39m ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!
[36m(RolloutWorker pid=25950)[39m 2022-04-01 12:32:40,051	ERROR worker.py:430 -- Exception raised in creation task: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=25950, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fae2ebf9640>)
[36m(RolloutWorker pid=25950)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 541, in __init__
[36m(RolloutWorker pid=25950)[39m     self.policy_dict = _determine_spaces_for_multi_agent_dict(
[36m(RolloutWorker pid=25950)[39m   File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py", line 1657, in _determine_spaces_for_multi_agent_dict
[36m(RolloutWorker pid=25950)[39m     raise ValueError(
[36m(RolloutWorker pid=25950)[39m ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!
Traceback (most recent call last):
  File "/Users/liwenyu/Documents/GitHub/RTDM/loadmodel.py", line 48, in <module>
    ray.tune.run(
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/tune.py", line 633, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [PPO_6804c_00000])
Traceback (most recent call last):
  File "/Users/liwenyu/Documents/GitHub/RTDM/loadmodel.py", line 48, in <module>
    ray.tune.run(
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ray/tune/tune.py", line 633, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [PPO_6804c_00000])