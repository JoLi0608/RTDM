Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 13       |
|    ep_rew_mean        | 13       |
| time/                 |          |
|    fps                | 983      |
|    iterations         | 100      |
|    time_elapsed       | 0        |
|    total_timesteps    | 500      |
| train/                |          |
|    entropy_loss       | -0.348   |
|    explained_variance | 0.702    |
|    learning_rate      | 0.0007   |
|    n_updates          | 99       |
|    policy_loss        | 0.105    |
|    value_loss         | 1.26     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 12.6     |
|    ep_rew_mean        | 12.6     |
| time/                 |          |
|    fps                | 1002     |
|    iterations         | 200      |
|    time_elapsed       | 0        |
|    total_timesteps    | 1000     |
| train/                |          |
|    entropy_loss       | -0.498   |
|    explained_variance | 0.626    |
|    learning_rate      | 0.0007   |
|    n_updates          | 199      |
|    policy_loss        | 0.0191   |
|    value_loss         | 11.1     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 14.2     |
|    ep_rew_mean        | 14.2     |
| time/                 |          |
|    fps                | 996      |
|    iterations         | 300      |
|    time_elapsed       | 1        |
|    total_timesteps    | 1500     |
| train/                |          |
|    entropy_loss       | -0.683   |
|    explained_variance | -0.00441 |
|    learning_rate      | 0.0007   |
|    n_updates          | 299      |
|    policy_loss        | 1.71     |
|    value_loss         | 8.1      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 16.5     |
|    ep_rew_mean        | 16.5     |
| time/                 |          |
|    fps                | 905      |
|    iterations         | 400      |
|    time_elapsed       | 2        |
|    total_timesteps    | 2000     |
| train/                |          |
|    entropy_loss       | -0.69    |
|    explained_variance | 0.0513   |
|    learning_rate      | 0.0007   |
|    n_updates          | 399      |
|    policy_loss        | 1.57     |
|    value_loss         | 7.16     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 19.4     |
|    ep_rew_mean        | 19.4     |
| time/                 |          |
|    fps                | 923      |
|    iterations         | 500      |
|    time_elapsed       | 2        |
|    total_timesteps    | 2500     |
| train/                |          |
|    entropy_loss       | -0.656   |
|    explained_variance | 0.287    |
|    learning_rate      | 0.0007   |
|    n_updates          | 499      |
|    policy_loss        | 1.46     |
|    value_loss         | 5.2      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 22.1     |
|    ep_rew_mean        | 22.1     |
| time/                 |          |
|    fps                | 951      |
|    iterations         | 600      |
|    time_elapsed       | 3        |
|    total_timesteps    | 3000     |
| train/                |          |
|    entropy_loss       | -0.677   |
|    explained_variance | 0.0109   |
|    learning_rate      | 0.0007   |
|    n_updates          | 599      |
|    policy_loss        | 1.12     |
|    value_loss         | 5.39     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 25.6     |
|    ep_rew_mean        | 25.6     |
| time/                 |          |
|    fps                | 970      |
|    iterations         | 700      |
|    time_elapsed       | 3        |
|    total_timesteps    | 3500     |
| train/                |          |
|    entropy_loss       | -0.681   |
|    explained_variance | 0.0024   |
|    learning_rate      | 0.0007   |
|    n_updates          | 699      |
|    policy_loss        | 1.24     |
|    value_loss         | 4.89     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 29.6     |
|    ep_rew_mean        | 29.6     |
| time/                 |          |
|    fps                | 982      |
|    iterations         | 800      |
|    time_elapsed       | 4        |
|    total_timesteps    | 4000     |
| train/                |          |
|    entropy_loss       | -0.651   |
|    explained_variance | 0.00665  |
|    learning_rate      | 0.0007   |
|    n_updates          | 799      |
|    policy_loss        | 1.15     |
|    value_loss         | 4.5      |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 32.8     |
|    ep_rew_mean        | 32.8     |
| time/                 |          |
|    fps                | 984      |
|    iterations         | 900      |
|    time_elapsed       | 4        |
|    total_timesteps    | 4500     |
| train/                |          |
|    entropy_loss       | -0.598   |
|    explained_variance | 0.0011   |
|    learning_rate      | 0.0007   |
|    n_updates          | 899      |
|    policy_loss        | 0.891    |
|    value_loss         | 3.98     |
------------------------------------
-------------------------------------
| rollout/              |           |
|    ep_len_mean        | 36.7      |
|    ep_rew_mean        | 36.7      |
| time/                 |           |
|    fps                | 978       |
|    iterations         | 1000      |
|    time_elapsed       | 5         |
|    total_timesteps    | 5000      |
| train/                |           |
|    entropy_loss       | -0.559    |
|    explained_variance | -0.000655 |
|    learning_rate      | 0.0007    |
|    n_updates          | 999       |
|    policy_loss        | 1.03      |
|    value_loss         | 3.49      |
-------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 40.2     |
|    ep_rew_mean        | 40.2     |
| time/                 |          |
|    fps                | 985      |
|    iterations         | 1100     |
|    time_elapsed       | 5        |
|    total_timesteps    | 5500     |
| train/                |          |
|    entropy_loss       | -0.541   |
|    explained_variance | 0.000905 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1099     |
|    policy_loss        | 1.12     |
|    value_loss         | 2.99     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 43.6     |
|    ep_rew_mean        | 43.6     |
| time/                 |          |
|    fps                | 996      |
|    iterations         | 1200     |
|    time_elapsed       | 6        |
|    total_timesteps    | 6000     |
| train/                |          |
|    entropy_loss       | -0.56    |
|    explained_variance | -0.0014  |
|    learning_rate      | 0.0007   |
|    n_updates          | 1199     |
|    policy_loss        | 0.593    |
|    value_loss         | 2.57     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 46.3     |
|    ep_rew_mean        | 46.3     |
| time/                 |          |
|    fps                | 1003     |
|    iterations         | 1300     |
|    time_elapsed       | 6        |
|    total_timesteps    | 6500     |
| train/                |          |
|    entropy_loss       | -0.547   |
|    explained_variance | -0.00719 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1299     |
|    policy_loss        | 0.356    |
|    value_loss         | 2.17     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 50.4     |
|    ep_rew_mean        | 50.4     |
| time/                 |          |
|    fps                | 1002     |
|    iterations         | 1400     |
|    time_elapsed       | 6        |
|    total_timesteps    | 7000     |
| train/                |          |
|    entropy_loss       | -0.588   |
|    explained_variance | 0.000696 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1399     |
|    policy_loss        | 0.556    |
|    value_loss         | 1.78     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 53.5     |
|    ep_rew_mean        | 53.5     |
| time/                 |          |
|    fps                | 1008     |
|    iterations         | 1500     |
|    time_elapsed       | 7        |
|    total_timesteps    | 7500     |
| train/                |          |
|    entropy_loss       | -0.501   |
|    explained_variance | 0.00089  |
|    learning_rate      | 0.0007   |
|    n_updates          | 1499     |
|    policy_loss        | 0.245    |
|    value_loss         | 1.42     |
------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 59.4     |
|    ep_rew_mean        | 59.4     |
| time/                 |          |
|    fps                | 1020     |
|    iterations         | 1600     |
|    time_elapsed       | 7        |
|    total_timesteps    | 8000     |
| train/                |          |
|    entropy_loss       | -0.566   |
|    explained_variance | 0.000193 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1599     |
|    policy_loss        | 0.312    |
|    value_loss         | 1.12     |
------------------------------------
-------------------------------------
| rollout/              |           |
|    ep_len_mean        | 62.9      |
|    ep_rew_mean        | 62.9      |
| time/                 |           |
|    fps                | 1026      |
|    iterations         | 1700      |
|    time_elapsed       | 8         |
|    total_timesteps    | 8500      |
| train/                |           |
|    entropy_loss       | -0.571    |
|    explained_variance | -6.26e-05 |
|    learning_rate      | 0.0007    |
|    n_updates          | 1699      |
|    policy_loss        | 0.439     |
|    value_loss         | 0.844     |
-------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 66.2     |
|    ep_rew_mean        | 66.2     |
| time/                 |          |
|    fps                | 1035     |
|    iterations         | 1800     |
|    time_elapsed       | 8        |
|    total_timesteps    | 9000     |
| train/                |          |
|    entropy_loss       | -0.489   |
|    explained_variance | 1.07e-06 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1799     |
|    policy_loss        | 0.23     |
|    value_loss         | 0.606    |
------------------------------------
-------------------------------------
| rollout/              |           |
|    ep_len_mean        | 72.3      |
|    ep_rew_mean        | 72.3      |
| time/                 |           |
|    fps                | 1040      |
|    iterations         | 1900      |
|    time_elapsed       | 9         |
|    total_timesteps    | 9500      |
| train/                |           |
|    entropy_loss       | -0.538    |
|    explained_variance | -0.000969 |
|    learning_rate      | 0.0007    |
|    n_updates          | 1899      |
|    policy_loss        | 0.22      |
|    value_loss         | 0.401     |
-------------------------------------
------------------------------------
| rollout/              |          |
|    ep_len_mean        | 76       |
|    ep_rew_mean        | 76       |
| time/                 |          |
|    fps                | 1047     |
|    iterations         | 2000     |
|    time_elapsed       | 9        |
|    total_timesteps    | 10000    |
| train/                |          |
|    entropy_loss       | -0.489   |
|    explained_variance | 3.12e-05 |
|    learning_rate      | 0.0007   |
|    n_updates          | 1999     |
|    policy_loss        | 0.256    |
|    value_loss         | 0.244    |
------------------------------------
difficulty level: 0
/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: [33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.
  warnings.warn(colorize("%s: %s" % ("WARN", msg % args), "yellow"))
[392.0, 253.0, 292.0, 364.0, 347.0, 260.0, 311.0, 358.0, 216.0, 271.0, 272.0, 359.0, 376.0, 220.0, 221.0, 326.0, 359.0, 406.0, 258.0, 291.0]
difficulty level: 1
[278.0, 379.0, 236.0, 287.0, 260.0, 287.0, 229.0, 234.0, 313.0, 224.0, 494.0, 252.0, 227.0, 260.0, 293.0, 288.0, 211.0, 276.0, 271.0, 314.0]
difficulty level: 2
[185.0, 188.0, 142.0, 112.0, 276.0, 105.0, 170.0, 268.0, 204.0, 413.0, 224.0, 153.0, 262.0, 85.0, 142.0, 174.0, 89.0, 115.0, 161.0, 145.0]
difficulty level: 3
[80.0, 185.0, 74.0, 104.0, 210.0, 109.0, 140.0, 182.0, 160.0, 220.0, 123.0, 35.0, 227.0, 108.0, 68.0, 110.0, 53.0, 83.0, 170.0, 152.0]
difficulty level: 4
[40.0, 40.0, 62.0, 93.0, 158.0, 36.0, 59.0, 189.0, 193.0, 229.0, 11.0, 82.0, 165.0, 65.0, 12.0, 127.0, 116.0, 78.0, 124.0, 202.0]
difficulty level: 5
[83.0, 118.0, 153.0, 91.0, 82.0, 66.0, 116.0, 45.0, 52.0, 9.0, 38.0, 95.0, 77.0, 22.0, 65.0, 166.0, 100.0, 16.0, 86.0, 86.0]
difficulty level: 6
[83.0, 109.0, 70.0, 55.0, 103.0, 26.0, 98.0, 80.0, 89.0, 146.0, 42.0, 80.0, 141.0, 107.0, 247.0, 11.0, 84.0, 70.0, 73.0, 78.0]
difficulty level: 7
[71.0, 63.0, 72.0, 73.0, 9.0, 9.0, 52.0, 105.0, 104.0, 40.0, 77.0, 87.0, 76.0, 72.0, 122.0, 72.0, 68.0, 73.0, 44.0, 51.0]
difficulty level: 8
[41.0, 13.0, 46.0, 82.0, 32.0, 86.0, 42.0, 36.0, 19.0, 76.0, 85.0, 118.0, 10.0, 19.0, 35.0, 77.0, 95.0, 137.0, 23.0, 72.0]
difficulty level: 9
[9.0, 18.0, 18.0, 82.0, 71.0, 50.0, 20.0, 81.0, 93.0, 27.0, 44.0, 81.0, 56.0, 12.0, 25.0, 12.0, 39.0, 56.0, 17.0, 81.0]
difficulty level: 10
[9.0, 9.0, 11.0, 63.0, 38.0, 12.0, 35.0, 87.0, 103.0, 11.0, 16.0, 32.0, 67.0, 43.0, 12.0, 19.0, 83.0, 68.0, 109.0, 51.0]
difficulty level: 11
[10.0, 9.0, 32.0, 10.0, 87.0, 50.0, 47.0, 23.0, 62.0, 60.0, 27.0, 46.0, 18.0, 34.0, 50.0, 23.0, 10.0, 57.0, 18.0, 70.0]
difficulty level: 12
[18.0, 55.0, 38.0, 10.0, 50.0, 17.0, 55.0, 81.0, 10.0, 13.0, 28.0, 57.0, 72.0, 45.0, 12.0, 31.0, 14.0, 61.0, 43.0, 24.0]
difficulty level: 13
[8.0, 9.0, 10.0, 9.0, 18.0, 11.0, 10.0, 18.0, 10.0, 80.0, 11.0, 13.0, 46.0, 10.0, 19.0, 58.0, 12.0, 41.0, 11.0, 19.0]
difficulty level: 14
[10.0, 9.0, 8.0, 116.0, 10.0, 38.0, 10.0, 8.0, 10.0, 11.0, 18.0, 26.0, 33.0, 10.0, 13.0, 46.0, 100.0, 10.0, 10.0, 70.0]
difficulty level: 15
[10.0, 10.0, 9.0, 9.0, 9.0, 44.0, 9.0, 11.0, 11.0, 38.0, 10.0, 39.0, 39.0, 12.0, 9.0, 11.0, 49.0, 9.0, 11.0, 9.0]
difficulty level: 16
[10.0, 9.0, 11.0, 10.0, 9.0, 9.0, 10.0, 13.0, 9.0, 8.0, 9.0, 9.0, 11.0, 74.0, 10.0, 12.0, 9.0, 10.0, 17.0, 9.0]
difficulty level: 17
[9.0, 10.0, 9.0, 10.0, 10.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 11.0, 9.0, 9.0, 10.0, 10.0]
difficulty level: 18
[10.0, 9.0, 9.0, 10.0, 9.0, 10.0, 9.0, 12.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 10.0, 10.0, 10.0, 9.0, 10.0]
difficulty level: 19
[9.0, 10.0, 9.0, 10.0, 10.0, 8.0, 10.0, 10.0, 10.0, 9.0, 10.0, 9.0, 10.0, 10.0, 10.0, 10.0, 9.0, 11.0, 9.0, 10.0]
final result: [307.6, 280.65, 180.65, 129.65, 104.05, 78.3, 89.6, 67.0, 57.2, 44.6, 43.9, 37.15, 36.7, 21.15, 28.3, 17.9, 13.4, 9.7, 9.8, 9.65]